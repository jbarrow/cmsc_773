{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from clpsych import store, data\n",
    "\n",
    "import codecs\n",
    "import os\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data from parse files (not Spacy format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized = {}\n",
    "i = 0\n",
    "\n",
    "base_i = i\n",
    "more = True\n",
    "while more:\n",
    "    if i % 10 == 0: print i\n",
    "    if i < base_i + 50 and os.path.isfile('parses/{}.parse'.format(i)):\n",
    "        docs, titles = read_parses('parses/{}.parse'.format(i))\n",
    "        keys = [key for key in docs.keys() if key]\n",
    "        for key in keys:\n",
    "            doc, title = [], []\n",
    "            for token in docs[key]:\n",
    "                doc.append(token)\n",
    "            for token in titles[key]:\n",
    "                title.append(token.lemma)\n",
    "            tokenized[key] = (title, doc)\n",
    "        i += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#including parse takes 6 hours and doesn't do anything\n",
    "config = {\n",
    "    'mask': './**/**/*.posts',\n",
    "    'train_mask': './**/**/TRAIN.txt',\n",
    "    'test_mask': './**/**/TEST.txt',\n",
    "    'dev_mask': './**/**/DEV.txt',\n",
    "    'sample_mask': './SAMPLE.txt',\n",
    "    #'parse':'./parses/*.parse',\n",
    "    #'parsed':True\n",
    "}\n",
    "\n",
    "load = store.Store('data.h5', config=config, overwrite = False)\n",
    "data = load.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this can be replaced with read_parses() if it saves \"tok.sents\" and \"tok.rank\"\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this can be replaced with read_parses() if it saves \"tok.sents\"\n",
    "#currently takes ~3 hours to run\n",
    "\n",
    "df = pandas.DataFrame(columns=('post_id', 'num_sent', 'avg_len', 'spelling', 'accuracy'))\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    #read with spacy, decode into unicode\n",
    "    spacy_doc = nlp(row['text'].decode(\"utf-8\"))\n",
    "    \n",
    "    #add tokens if their spacy rank isn't 0 (we could set a threshold here as well)\n",
    "    no_typos = [tok for tok in spacy_doc if tok.rank!=0]    \n",
    "    \n",
    "    #simple counts (number of sentences, and avg lengh of sentence)\n",
    "    num_sent = len(list(spacy_doc.sents))\n",
    "    avg_len_sent =  sum([len(sent) for sent in list(spacy_doc.sents)])/len(list(spacy_doc.sents))  if len(list(spacy_doc.sents))> 0 else 0\n",
    "    \n",
    "    #most appear to have values over 90% (aka little typos).  Chose to set 0 length docs to 1.  \n",
    "    accuracy = float(len(no_typos))/len(spacy_doc) if len(spacy_doc) > 0 else 1\n",
    "    \n",
    "    #append to new DF in the same row order\n",
    "    df.loc[index] = row['post_id'], num_sent, avg_len_sent, no_typos, accuracy\n",
    "\n",
    "print df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO BoW BoDependencies, Subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store.create_doc_feature(store.data ,df['post_id', 'num_sent', 'avg_len', 'spelling', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potpourri Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2594, 736, 683, 4, 8007, 405, 355, 49, 3075, 0, 264328, 80517, 436651, 0, 465]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#can we trust .rank?  I think yes.  High ranking words are pronouns, punctuation.  Low ranking words are proper nouns.  Misspellings are generally 0s (somethines high numbers)\n",
    "words = nlp(u'suicide death die I ugh hate myself me wtf asfab beelzebub shakespeare javert misppeling reddit')\n",
    "\n",
    "[tok.rank for tok in words]\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
